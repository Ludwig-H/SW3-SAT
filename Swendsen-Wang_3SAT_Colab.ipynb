{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KtKer9gg7Il"
   },
   "source": [
    "# Stochastic Higher-Order Swendsen-Wang vs WalkSAT\n",
    "\n",
    "This notebook compares our **Stochastic Cluster Monte Carlo** algorithm against the industry standard for Random SAT: **WalkSAT**.\n",
    "\n",
    "## The Contenders\n",
    "1.  **Stochastic Swendsen-Wang (Ours)**:\n",
    "    *   Physics-based (Cluster Dynamics).\n",
    "    *   Uses geometric frustration and percolation.\n",
    "    *   **New**: Uses **Exact Hamiltonian Cluster Updates** (Exact Energy Delta) for decision.\n",
    "    *   **Schedule**: Logarithmic annealing (dense near $\\omega_{max}$).\n",
    "    *   Runs on GPU (Massively Parallel).\n",
    "2.  **WalkSAT (Reference)**:\n",
    "    *   Stochastic Local Search.\n",
    "    *   Greedy + Noise heuristic.\n",
    "    *   Runs on CPU (Sequential, fast flips)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IIfZsdIYg7Iq"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU Detected: 1 device(s)\n",
      "Environment Ready.\n"
     ]
    }
   ],
   "source": [
    "# @title 1. Environment & GPU Setup\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import tarfile\n",
    "import io\n",
    "import gzip\n",
    "import random\n",
    "\n",
    "# Ensure CuPy is available\n",
    "try:\n",
    "    import cupy as cp\n",
    "    import cupyx.scipy.sparse as cpx\n",
    "    import cupyx.scipy.sparse.csgraph as cpx_graph\n",
    "    print(f\"GPU Detected: {cp.cuda.runtime.getDeviceCount()} device(s)\")\n",
    "except ImportError:\n",
    "    print(\"Installing CuPy...\")\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'cupy-cuda12x'])\n",
    "    import cupy as cp\n",
    "    import cupyx.scipy.sparse as cpx\n",
    "    import cupyx.scipy.sparse.csgraph as cpx_graph\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "print(\"Environment Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": null
   },
   "outputs": [],
   "source": [
    "# @title 2. Data Generators (Random & SATLIB)\n",
    "\n",
    "def generate_random_3sat(N, alpha, seed=None):\n",
    "    if seed is not None: np.random.seed(seed)\n",
    "    M = int(N * alpha)\n",
    "    vars = np.random.randint(1, N + 1, size=(M, 3))\n",
    "    signs = np.random.choice([-1, 1], size=(M, 3))\n",
    "    return vars * signs, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": null
   },
   "outputs": [],
   "source": [
    "# @title 3. The Solver: `StochasticSwendsenWangGPU`\n",
    "\n",
    "class StochasticSwendsenWangGPU:\n",
    "    def __init__(self, clauses_np, N, beta_scale=10.0):\n",
    "        self.N = N\n",
    "        self.M = len(clauses_np)\n",
    "        self.clauses = cp.array(clauses_np)\n",
    "        self.GHOST = 0\n",
    "        self.beta_scale = beta_scale\n",
    "\n",
    "        # Literals\n",
    "        self.lits_idx = cp.abs(self.clauses)\n",
    "        self.lits_sign = cp.sign(self.clauses)\n",
    "\n",
    "        # Interactions\n",
    "        s = self.lits_sign\n",
    "        j01 = cp.where(s[:, 0] == s[:, 1], -1, 1)\n",
    "        j12 = cp.where(s[:, 1] == s[:, 2], -1, 1)\n",
    "        j20 = cp.where(s[:, 2] == s[:, 0], -1, 1)\n",
    "        self.J_tri = cp.stack([j01, j12, j20], axis=1).astype(cp.int8)\n",
    "        self.J_tetra = s.astype(cp.int8)\n",
    "\n",
    "        # State\n",
    "        self.sigma = cp.random.choice(cp.array([-1, 1], dtype=cp.int8), size=N+1)\n",
    "        self.sigma[0] = 1\n",
    "\n",
    "    def energy_check(self, omega):\n",
    "        spins = self.sigma[self.lits_idx]\n",
    "        is_lit_sat = (spins == self.lits_sign)\n",
    "        is_clause_sat = cp.any(is_lit_sat, axis=1)\n",
    "        unsat_frac = 1.0 - cp.mean(is_clause_sat)\n",
    "        return unsat_frac\n",
    "\n",
    "    def step(self, omega):\n",
    "        # 1. Calculate Clause Status\n",
    "        c_spins = self.sigma[self.lits_idx]\n",
    "        lit_is_sat = (c_spins == self.J_tetra)\n",
    "        num_lit_sat = cp.sum(lit_is_sat, axis=1)\n",
    "\n",
    "        is_fully_sat = (num_lit_sat == 3)\n",
    "        is_unsat = (num_lit_sat == 0) # High Energy / UNSAT Clause\n",
    "\n",
    "        # Triangle Internal Status\n",
    "        s0, s1, s2 = c_spins[:, 0], c_spins[:, 1], c_spins[:, 2]\n",
    "        sat0 = (s0 * s1 * self.J_tri[:, 0] == 1)\n",
    "        sat1 = (s1 * s2 * self.J_tri[:, 1] == 1)\n",
    "        sat2 = (s2 * s0 * self.J_tri[:, 2] == 1)\n",
    "        sat_mask = cp.stack([sat0, sat1, sat2], axis=1)\n",
    "        num_sat_tri = cp.sum(sat_mask, axis=1)\n",
    "\n",
    "        # Low Energy Triangle = 2 satisfied edges (occurs when 1 or 2 lits sat)\n",
    "        is_low_energy = (num_sat_tri == 2)\n",
    "\n",
    "        # 2. Marking Step\n",
    "        marked_vars = cp.zeros(self.N + 1, dtype=bool)\n",
    "        if cp.any(is_unsat):\n",
    "            unsat_vars = self.lits_idx[is_unsat].flatten()\n",
    "            marked_vars[unsat_vars] = True\n",
    "\n",
    "        lit_marked = marked_vars[self.lits_idx]\n",
    "        num_marked = cp.sum(lit_marked, axis=1) # 0, 1, 2, or 3\n",
    "\n",
    "        # 3. Randomness\n",
    "        P = 1.0 - cp.exp(-omega)\n",
    "        rand_vals = cp.random.random(self.M, dtype=cp.float32)\n",
    "\n",
    "        src_nodes = []\n",
    "        dst_nodes = []\n",
    "\n",
    "        # --- Tetra & Triangle Logic (Swendsen-Wang Edges) ---\n",
    "\n",
    "        # --- A. Tetrahedron Logic (Fully SAT) ---\n",
    "        mask_A = is_fully_sat & (rand_vals < P)\n",
    "        if cp.any(mask_A):\n",
    "            idx_A = cp.where(mask_A)[0]\n",
    "            n_marked_A = num_marked[idx_A]\n",
    "            # Case A1: 3 Marked\n",
    "            mask_A1 = (n_marked_A == 3)\n",
    "            if cp.any(mask_A1):\n",
    "                idx_A1 = idx_A[mask_A1]\n",
    "                r_sel = cp.random.randint(0, 3, size=len(idx_A1))\n",
    "                targets = self.lits_idx[idx_A1, r_sel]\n",
    "                src_nodes.append(cp.zeros_like(targets))\n",
    "                dst_nodes.append(targets)\n",
    "            # Case A2: < 3 Marked\n",
    "            mask_A2 = (n_marked_A < 3)\n",
    "            if cp.any(mask_A2):\n",
    "                idx_A2 = idx_A[mask_A2]\n",
    "                unmarked_mask = ~lit_marked[idx_A2]\n",
    "                rows, cols = cp.where(unmarked_mask)\n",
    "                clause_indices = idx_A2[rows]\n",
    "                targets = self.lits_idx[clause_indices, cols]\n",
    "                src_nodes.append(cp.zeros_like(targets))\n",
    "                dst_nodes.append(targets)\n",
    "\n",
    "        # --- B. Triangle Logic (Low Energy & NOT Fully Sat) ---\n",
    "        mask_B = is_low_energy & (~is_fully_sat) & (rand_vals < P)\n",
    "        if cp.any(mask_B):\n",
    "            idx_B = cp.where(mask_B)[0]\n",
    "            n_marked_B = num_marked[idx_B]\n",
    "\n",
    "            # Case B3\n",
    "            mask_B3 = (n_marked_B == 3)\n",
    "            if cp.any(mask_B3):\n",
    "                idx_B3 = idx_B[mask_B3]\n",
    "                sat_lits_B3 = lit_is_sat[idx_B3]\n",
    "                r_sel = cp.random.random(sat_lits_B3.shape, dtype=cp.float32) * sat_lits_B3\n",
    "                chosen_col = cp.argmax(r_sel, axis=1)\n",
    "                targets = self.lits_idx[idx_B3, chosen_col]\n",
    "                src_nodes.append(cp.zeros_like(targets))\n",
    "                dst_nodes.append(targets)\n",
    "            # Case B2\n",
    "            mask_B2 = (n_marked_B == 2)\n",
    "            if cp.any(mask_B2):\n",
    "                idx_B2 = idx_B[mask_B2]\n",
    "                unmarked_col = cp.argmin(lit_marked[idx_B2], axis=1)\n",
    "                row_ids = cp.arange(len(idx_B2))\n",
    "                is_unmarked_sat = lit_is_sat[idx_B2, unmarked_col]\n",
    "                # B2.1\n",
    "                if cp.any(is_unmarked_sat):\n",
    "                    sub_idx = row_ids[is_unmarked_sat]\n",
    "                    real_idx = idx_B2[sub_idx]\n",
    "                    cols = unmarked_col[sub_idx]\n",
    "                    targets = self.lits_idx[real_idx, cols]\n",
    "                    src_nodes.append(cp.zeros_like(targets))\n",
    "                    dst_nodes.append(targets)\n",
    "                # B2.2\n",
    "                is_unmarked_unsat = ~is_unmarked_sat\n",
    "                if cp.any(is_unmarked_unsat):\n",
    "                    sub_idx = row_ids[is_unmarked_unsat]\n",
    "                    real_idx = idx_B2[sub_idx]\n",
    "                    forbidden_edge = unmarked_col[sub_idx]\n",
    "                    c_sat_mask = sat_mask[real_idx]\n",
    "                    temp_mask = c_sat_mask.copy()\n",
    "                    temp_mask[cp.arange(len(real_idx)), forbidden_edge] = False\n",
    "                    target_edge = cp.argmax(temp_mask, axis=1)\n",
    "                    lits = self.lits_idx[real_idx]\n",
    "                    l0, l1, l2 = lits[:,0], lits[:,1], lits[:,2]\n",
    "                    s_e = cp.where(target_edge==0, l0, cp.where(target_edge==1, l1, l2))\n",
    "                    d_e = cp.where(target_edge==0, l1, cp.where(target_edge==1, l2, l0))\n",
    "                    src_nodes.append(s_e)\n",
    "                    dst_nodes.append(d_e)\n",
    "            # Case B1\n",
    "            mask_B1 = (n_marked_B == 1)\n",
    "            if cp.any(mask_B1):\n",
    "                idx_B1 = idx_B[mask_B1]\n",
    "                marked_col = cp.argmax(lit_marked[idx_B1], axis=1)\n",
    "                row_ids = cp.arange(len(idx_B1))\n",
    "                is_opp_sat = sat_mask[idx_B1, marked_col]\n",
    "                # B1.1\n",
    "                if cp.any(is_opp_sat):\n",
    "                    sub_idx = row_ids[is_opp_sat]\n",
    "                    real_idx = idx_B1[sub_idx]\n",
    "                    target_edge = marked_col[sub_idx]\n",
    "                    lits = self.lits_idx[real_idx]\n",
    "                    l0, l1, l2 = lits[:,0], lits[:,1], lits[:,2]\n",
    "                    s_e = cp.where(target_edge==0, l0, cp.where(target_edge==1, l1, l2))\n",
    "                    d_e = cp.where(target_edge==0, l1, cp.where(target_edge==1, l2, l0))\n",
    "                    src_nodes.append(s_e)\n",
    "                    dst_nodes.append(d_e)\n",
    "                # B1.2\n",
    "                is_opp_unsat = ~is_opp_sat\n",
    "                if cp.any(is_opp_unsat):\n",
    "                    sub_idx = row_ids[is_opp_unsat]\n",
    "                    real_idx = idx_B1[sub_idx]\n",
    "                    m_col = marked_col[sub_idx]\n",
    "                    is_marked_lit_sat = lit_is_sat[real_idx, m_col]\n",
    "                    # B1.2.a\n",
    "                    mask_a = (~is_marked_lit_sat)\n",
    "                    if cp.any(mask_a):\n",
    "                        idx_a = real_idx[mask_a]\n",
    "                        mc = m_col[mask_a]\n",
    "                        r_choice = cp.random.randint(0, 2, size=len(idx_a))\n",
    "                        offset = r_choice + 1\n",
    "                        target_col = (mc + offset) % 3\n",
    "                        targets = self.lits_idx[idx_a, target_col]\n",
    "                        src_nodes.append(cp.zeros_like(targets))\n",
    "                        dst_nodes.append(targets)\n",
    "                    # B1.2.b\n",
    "                    mask_b = (is_marked_lit_sat)\n",
    "                    if cp.any(mask_b):\n",
    "                        idx_b = real_idx[mask_b]\n",
    "                        mc = m_col[mask_b]\n",
    "                        targets = self.lits_idx[idx_b, mc]\n",
    "                        src_nodes.append(cp.zeros_like(targets))\n",
    "                        dst_nodes.append(targets)\n",
    "            # Case B0\n",
    "            mask_B0 = (n_marked_B == 0)\n",
    "            if cp.any(mask_B0):\n",
    "                idx_B0 = idx_B[mask_B0]\n",
    "                sub_sat = sat_mask[idx_B0]\n",
    "                r_vals_B = rand_vals[mask_B][mask_B0]\n",
    "                pick_first = (r_vals_B < (P / 2.0))\n",
    "                idx_1st = cp.argmax(sub_sat, axis=1)\n",
    "                temp = sub_sat.copy()\n",
    "                temp[cp.arange(len(idx_B0)), idx_1st] = False\n",
    "                idx_2nd = cp.argmax(temp, axis=1)\n",
    "                chosen_edge_idx = cp.where(pick_first, idx_1st, idx_2nd)\n",
    "                lits = self.lits_idx[idx_B0]\n",
    "                l0, l1, l2 = lits[:,0], lits[:,1], lits[:,2]\n",
    "                s_e = cp.where(chosen_edge_idx==0, l0, cp.where(chosen_edge_idx==1, l1, l2))\n",
    "                d_e = cp.where(chosen_edge_idx==0, l1, cp.where(chosen_edge_idx==1, l2, l0))\n",
    "                src_nodes.append(s_e)\n",
    "                dst_nodes.append(d_e)\n",
    "\n",
    "        # --- 4. Cluster & Flip ---\n",
    "        c1_frac = 0.0\n",
    "        c2_frac = 0.0\n",
    "\n",
    "        if len(src_nodes) > 0:\n",
    "            all_src = cp.concatenate(src_nodes)\n",
    "            all_dst = cp.concatenate(dst_nodes)\n",
    "\n",
    "            data = cp.ones(len(all_src), dtype=cp.float32)\n",
    "            adj = cpx.coo_matrix((data, (all_src, all_dst)), shape=(self.N+1, self.N+1), dtype=cp.float32)\n",
    "            n_comps, labels = cpx_graph.connected_components(adj, directed=False)\n",
    "\n",
    "            # Percolation Stats\n",
    "            comp_sizes = cp.bincount(labels)\n",
    "            sorted_sizes = cp.sort(comp_sizes)[::-1]\n",
    "            c1_size = sorted_sizes[0]\n",
    "            c2_size = sorted_sizes[1] if n_comps > 1 else 0.0\n",
    "            c1_frac = c1_size / float(self.N + 1)\n",
    "            c2_frac = c2_size / float(self.N + 1)\n",
    "\n",
    "            # --- EXACT HAMILTONIAN CLUSTER UPDATE ---\n",
    "            cluster_votes = cp.zeros(n_comps, dtype=cp.int32)\n",
    "\n",
    "            lit_clusters = labels[self.lits_idx] # (M, 3)\n",
    "            is_clause_sat_curr = cp.any(lit_is_sat, axis=1)\n",
    "\n",
    "            # Loop over columns (literals) to simulate flip\n",
    "            for col in range(3):\n",
    "                target_clusters = lit_clusters[:, col]\n",
    "\n",
    "                # Check for duplicates with previous cols\n",
    "                is_duplicate = cp.zeros(self.M, dtype=bool)\n",
    "                for prev_col in range(col):\n",
    "                    is_duplicate |= (lit_clusters[:, prev_col] == target_clusters)\n",
    "\n",
    "                mask_process = ~is_duplicate\n",
    "                if not cp.any(mask_process):\n",
    "                    continue\n",
    "\n",
    "                mask_in_cluster = (lit_clusters == target_clusters[:, None]) # (M, 3)\n",
    "                new_lit_sat = lit_is_sat.copy()\n",
    "                new_lit_sat[mask_in_cluster] = ~new_lit_sat[mask_in_cluster]\n",
    "\n",
    "                is_clause_sat_new = cp.any(new_lit_sat, axis=1)\n",
    "                delta = is_clause_sat_new.astype(cp.int32) - is_clause_sat_curr.astype(cp.int32)\n",
    "\n",
    "                valid_indices = cp.where(mask_process)[0]\n",
    "                valid_clusters = target_clusters[valid_indices]\n",
    "                valid_deltas = delta[valid_indices]\n",
    "\n",
    "                cp.add.at(cluster_votes, valid_clusters, valid_deltas)\n",
    "\n",
    "            # 3. Decision (Logistic)\n",
    "            scores = cluster_votes.astype(cp.float32) * omega * self.beta_scale\n",
    "            probs = 1.0 / (1.0 + cp.exp(-scores))\n",
    "\n",
    "            r_vals = cp.random.random(n_comps, dtype=cp.float32)\n",
    "            do_flip = cp.where(r_vals < probs, -1, 1).astype(cp.int8)\n",
    "\n",
    "            # 4. Apply\n",
    "            flip_vector = do_flip[labels]\n",
    "            self.sigma *= flip_vector\n",
    "\n",
    "            if self.sigma[self.GHOST] == -1:\n",
    "                self.sigma *= -1\n",
    "        else:\n",
    "            c1_frac = 1.0 / (self.N + 1)\n",
    "            c2_frac = 1.0 / (self.N + 1)\n",
    "            flips = cp.random.choice(cp.array([-1, 1], dtype=cp.int8), size=self.N+1)\n",
    "            self.sigma *= flips\n",
    "            if self.sigma[self.GHOST] == -1:\n",
    "                self.sigma *= -1\n",
    "\n",
    "        return self.energy_check(omega), c1_frac, c2_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": null
   },
   "outputs": [],
   "source": [
    "# @title 3b. The New Solver: `SwendsenWangGlauberGPU`\n",
    "\n",
    "class SwendsenWangGlauberGPU:\n",
    "    def __init__(self, clauses_np, N, beta_scale=10.0, steps_flips=1000, dynamics=\"Metropolis-Hastings\"):\n",
    "        self.N = N\n",
    "        self.M = len(clauses_np)\n",
    "        self.clauses = cp.array(clauses_np)\n",
    "        self.GHOST = 0\n",
    "        self.beta_scale = beta_scale\n",
    "        self.steps_flips = steps_flips\n",
    "        self.dynamics = dynamics  # \"Metropolis-Hastings\" or \"Glauber\"\n",
    "\n",
    "        # Literals info\n",
    "        self.lits_idx = cp.abs(self.clauses)\n",
    "        self.lits_sign = cp.sign(self.clauses).astype(cp.int8)\n",
    "\n",
    "        # Triangle Interactions (J_tri)\n",
    "        # We implicitly consider the clause as a triangle of interactions between literals.\n",
    "        # Edge (0,1), (1,2), (2,0).\n",
    "        s = self.lits_sign\n",
    "        j01 = cp.where(s[:, 0] == s[:, 1], -1, 1)\n",
    "        j12 = cp.where(s[:, 1] == s[:, 2], -1, 1)\n",
    "        j20 = cp.where(s[:, 2] == s[:, 0], -1, 1)\n",
    "        self.J_tri = cp.stack([j01, j12, j20], axis=1).astype(cp.int8)\n",
    "\n",
    "        # State (Ghost at index 0 is always 1)\n",
    "        self.sigma = cp.random.choice(cp.array([-1, 1], dtype=cp.int8), size=N+1)\n",
    "        self.sigma[0] = 1\n",
    "\n",
    "    def energy_check(self):\n",
    "        spins = self.sigma[self.lits_idx]\n",
    "        is_lit_sat = (spins == self.lits_sign)\n",
    "        is_clause_sat = cp.any(is_lit_sat, axis=1)\n",
    "        return 1.0 - cp.mean(is_clause_sat)\n",
    "\n",
    "    def step(self, omega):\n",
    "        # --- 1. CLUSTERING STEP (Swendsen-Wang) ---\n",
    "        \n",
    "        # A. Calculate Status\n",
    "        c_spins = self.sigma[self.lits_idx]\n",
    "        lit_is_sat = (c_spins == self.lits_sign)\n",
    "        num_lit_sat = cp.sum(lit_is_sat, axis=1)\n",
    "\n",
    "        # Clauses fully satisfied (3 literals satisfied)\n",
    "        is_fully_sat = (num_lit_sat == 3) \n",
    "        \n",
    "        # Triangle Status (Edges satisfied)\n",
    "        s0, s1, s2 = c_spins[:, 0], c_spins[:, 1], c_spins[:, 2]\n",
    "        sat0 = (s0 * s1 * self.J_tri[:, 0] == 1)\n",
    "        sat1 = (s1 * s2 * self.J_tri[:, 1] == 1)\n",
    "        sat2 = (s2 * s0 * self.J_tri[:, 2] == 1)\n",
    "        sat_mask = cp.stack([sat0, sat1, sat2], axis=1)\n",
    "        num_sat_tri = cp.sum(sat_mask, axis=1)\n",
    "        \n",
    "        # Low Energy Triangles (Exactly 2 edges satisfied)\n",
    "        is_low_energy = (num_sat_tri == 2)\n",
    "\n",
    "        # B. Generate Edges\n",
    "        P = 1.0 - cp.exp(-omega)\n",
    "        rand_vals = cp.random.random(self.M, dtype=cp.float32)\n",
    "        \n",
    "        src_nodes = []\n",
    "        dst_nodes = []\n",
    "\n",
    "        # --- B1. Ghost Connections (Fully SAT Clauses) ---\n",
    "        # If freeze: pick ONE literal randomly based on rand_vals segments [0, P/3), [P/3, 2P/3), [2P/3, P)\n",
    "        mask_G = is_fully_sat & (rand_vals < P)\n",
    "        if cp.any(mask_G):\n",
    "            idx_G = cp.where(mask_G)[0]\n",
    "            r_vals_G = rand_vals[idx_G]\n",
    "            \n",
    "            # Determine column 0, 1, or 2 based on where r_vals_G falls in [0, P]\n",
    "            # Thresholds\n",
    "            P_3 = P / 3.0\n",
    "            \n",
    "            # col = 0 if r < P/3, 1 if P/3 <= r < 2P/3, 2 if r >= 2P/3\n",
    "            # Use sum of comparisons for branchless selection\n",
    "            col_choice = (r_vals_G >= P_3).astype(cp.int8) + (r_vals_G >= 2 * P_3).astype(cp.int8)\n",
    "            \n",
    "            targets = self.lits_idx[idx_G, col_choice]\n",
    "            \n",
    "            src_nodes.append(cp.zeros_like(targets)) # Connect to Ghost (0)\n",
    "            dst_nodes.append(targets)\n",
    "\n",
    "        # --- B2. Internal Edges (Low Energy Triangles) ---\n",
    "        # If freeze: pick ONE of the TWO satisfied edges based on rand_vals segments [0, P/2), [P/2, P)\n",
    "        mask_T = is_low_energy & (rand_vals < P)\n",
    "        if cp.any(mask_T):\n",
    "            idx_T = cp.where(mask_T)[0]\n",
    "            r_vals_T = rand_vals[idx_T]\n",
    "            \n",
    "            # Identify the two satisfied edges. \n",
    "            # sat_mask[idx_T] has exactly two Trues per row.\n",
    "            sub_sat = sat_mask[idx_T]\n",
    "            \n",
    "            # Find index of the first True (0, 1, or 2)\n",
    "            idx_1st = cp.argmax(sub_sat, axis=1)\n",
    "            \n",
    "            # Find index of the second True. \n",
    "            # Sum of indices (0+1=1, 0+2=2, 1+2=3). \n",
    "            # The sum of all satisfied indices is sum(sub_sat * [0,1,2]).\n",
    "            # So 2nd index = Total_Sum - 1st_Index.\n",
    "            idx_sum = cp.sum(sub_sat * cp.array([0, 1, 2], dtype=cp.int8), axis=1)\n",
    "            idx_2nd = idx_sum - idx_1st\n",
    "            \n",
    "            # Selection: First edge if r < P/2, else Second edge\n",
    "            P_2 = P / 2.0\n",
    "            pick_first = (r_vals_T < P_2)\n",
    "            \n",
    "            chosen_edge_idx = cp.where(pick_first, idx_1st, idx_2nd)\n",
    "            \n",
    "            lits = self.lits_idx[idx_T]\n",
    "            l0, l1, l2 = lits[:,0], lits[:,1], lits[:,2]\n",
    "            \n",
    "            # edge 0: (l0, l1), edge 1: (l1, l2), edge 2: (l2, l0)\n",
    "            s_e = cp.where(chosen_edge_idx==0, l0, cp.where(chosen_edge_idx==1, l1, l2))\n",
    "            d_e = cp.where(chosen_edge_idx==0, l1, cp.where(chosen_edge_idx==1, l2, l0))\n",
    "            \n",
    "            src_nodes.append(s_e)\n",
    "            dst_nodes.append(d_e)\n",
    "\n",
    "        # C. Connected Components\n",
    "        if len(src_nodes) > 0:\n",
    "            all_src = cp.concatenate(src_nodes)\n",
    "            all_dst = cp.concatenate(dst_nodes)\n",
    "            data = cp.ones(len(all_src), dtype=cp.float32)\n",
    "            # Ensure size is N+1\n",
    "            adj = cpx.coo_matrix((data, (all_src, all_dst)), shape=(self.N+1, self.N+1), dtype=cp.float32)\n",
    "            n_comps, labels = cpx_graph.connected_components(adj, directed=False)\n",
    "        else:\n",
    "            n_comps = self.N + 1\n",
    "            labels = cp.arange(self.N + 1, dtype=cp.int32)\n",
    "\n",
    "        # Stats\n",
    "        comp_sizes = cp.bincount(labels)\n",
    "        sorted_sizes = cp.sort(comp_sizes)[::-1]\n",
    "        c1_frac = sorted_sizes[0] / (self.N + 1)\n",
    "        c2_frac = sorted_sizes[1] / (self.N + 1) if n_comps > 1 else 0.0\n",
    "\n",
    "        # --- 2. DYNAMICS (Metropolis/Glauber on Clusters) ---\n",
    "        \n",
    "        # Optimization: Build Sparse Lookup Tables (CSR)\n",
    "        # 1. Cluster -> Variables\n",
    "        # This allows O(1) retrieval of all variables in a cluster\n",
    "        # sort_indices = cp.argsort(labels) # Not strictly needed for CSR but good for order\n",
    "        # We use a sparse matrix where rows=cluster_id, cols=var_idx\n",
    "        data_v = cp.ones(self.N + 1, dtype=cp.bool_)\n",
    "        cluster_to_vars = cpx.coo_matrix(\n",
    "            (data_v, (labels, cp.arange(self.N + 1))), \n",
    "            shape=(n_comps, self.N + 1)\n",
    "        ).tocsr()\n",
    "\n",
    "        # 2. Cluster -> Clauses\n",
    "        # lit_clusters is (M, 3). We want to map ClusterID -> ClauseIDs\n",
    "        # Flatten to coordinate format\n",
    "        flat_clusters = lit_clusters.flatten()\n",
    "        flat_clauses = cp.repeat(cp.arange(self.M), 3)\n",
    "        data_c = cp.ones(len(flat_clusters), dtype=cp.bool_)\n",
    "        \n",
    "        # Note: A clause might be listed multiple times for the same cluster if multiple lits are in it.\n",
    "        # CSR conversion sums duplicates by default, or we can treat as boolean presence.\n",
    "        cluster_to_clauses = cpx.coo_matrix(\n",
    "            (data_c, (flat_clusters, flat_clauses)), \n",
    "            shape=(n_comps, self.M)\n",
    "        ).tocsr()\n",
    "\n",
    "        ghost_label = labels[0]\n",
    "        unique_labels = cp.unique(labels)\n",
    "        valid_clusters = unique_labels[unique_labels != ghost_label]\n",
    "        num_valid = len(valid_clusters)\n",
    "\n",
    "        if num_valid > 0:\n",
    "            target_indices = cp.random.randint(0, num_valid, size=self.steps_flips)\n",
    "            chosen_clusters = valid_clusters[target_indices]\n",
    "            r_accepts = cp.random.random(self.steps_flips, dtype=cp.float32)\n",
    "\n",
    "            # Loop for dynamics\n",
    "            for i in range(self.steps_flips):\n",
    "                c_id = chosen_clusters[i]\n",
    "                \n",
    "                # --- FAST LOOKUP ---\n",
    "                # Get relevant clause indices directly from CSR\n",
    "                start_ptr_c = cluster_to_clauses.indptr[c_id]\n",
    "                end_ptr_c = cluster_to_clauses.indptr[c_id+1]\n",
    "                \n",
    "                if start_ptr_c == end_ptr_c:\n",
    "                    # Cluster not connected to any clause (isolated vars)\n",
    "                    # Just flip vars, Delta E is 0\n",
    "                    start_ptr_v = cluster_to_vars.indptr[c_id]\n",
    "                    end_ptr_v = cluster_to_vars.indptr[c_id+1]\n",
    "                    vars_idx = cluster_to_vars.indices[start_ptr_v:end_ptr_v]\n",
    "                    self.sigma[vars_idx] *= -1\n",
    "                    continue\n",
    "\n",
    "                clause_idx = cluster_to_clauses.indices[start_ptr_c:end_ptr_c]\n",
    "\n",
    "                # Subset of clauses\n",
    "                sub_lits_idx = self.lits_idx[clause_idx]\n",
    "                sub_lits_sign = self.lits_sign[clause_idx]\n",
    "                sub_sigma = self.sigma[sub_lits_idx] # Gather sigma values\n",
    "                \n",
    "                # Current Satisfaction\n",
    "                is_sat_curr = cp.any(sub_sigma == sub_lits_sign, axis=1)\n",
    "                \n",
    "                # Proposed Satisfaction\n",
    "                # We need to flip ONLY the variables belonging to c_id.\n",
    "                # Which literals in these clauses belong to c_id?\n",
    "                # We can re-check the cluster map locally\n",
    "                sub_lit_clusters = lit_clusters[clause_idx]\n",
    "                mask_in_cluster = (sub_lit_clusters == c_id)\n",
    "                \n",
    "                proposed_sigma = sub_sigma.copy()\n",
    "                proposed_sigma[mask_in_cluster] *= -1\n",
    "                \n",
    "                is_sat_new = cp.any(proposed_sigma == sub_lits_sign, axis=1)\n",
    "                \n",
    "                # Delta E\n",
    "                unsat_curr = cp.sum(~is_sat_curr)\n",
    "                unsat_new = cp.sum(~is_sat_new)\n",
    "                delta_E = unsat_new - unsat_curr \n",
    "                \n",
    "                accept = False\n",
    "                if self.dynamics == \"Metropolis-Hastings\":\n",
    "                    if delta_E <= 0:\n",
    "                        accept = True\n",
    "                    else:\n",
    "                        prob = cp.exp(-delta_E * omega * self.beta_scale)\n",
    "                        if r_accepts[i] < prob:\n",
    "                            accept = True\n",
    "                elif self.dynamics == \"Glauber\":\n",
    "                    prob = 1.0 / (1.0 + cp.exp(delta_E * omega * self.beta_scale))\n",
    "                    if r_accepts[i] < prob:\n",
    "                        accept = True\n",
    "                \n",
    "                if accept:\n",
    "                    # FAST UPDATE: Get variables from CSR\n",
    "                    start_ptr_v = cluster_to_vars.indptr[c_id]\n",
    "                    end_ptr_v = cluster_to_vars.indptr[c_id+1]\n",
    "                    vars_idx = cluster_to_vars.indices[start_ptr_v:end_ptr_v]\n",
    "                    \n",
    "                    self.sigma[vars_idx] *= -1\n",
    "\n",
    "        return self.energy_check(), c1_frac, c2_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": null
   },
   "outputs": [],
   "source": [
    "# @title 4. Baseline: `WalkSAT` (CPU Optimized)\n",
    "class WalkSAT:\n",
    "    def __init__(self, clauses_np, N):\n",
    "        self.N = N\n",
    "        self.clauses = clauses_np # NumPy (CPU)\n",
    "        self.M = len(clauses_np)\n",
    "\n",
    "        # Precompute lookups for break-count (simplification: simple evaluation)\n",
    "        self.vars_in_clauses = [[] for _ in range(N + 1)]\n",
    "        for m, clause in enumerate(self.clauses):\n",
    "            for lit in clause:\n",
    "                self.vars_in_clauses[abs(lit)].append(m)\n",
    "\n",
    "        # Random init\n",
    "        self.sigma = np.random.choice([-1, 1], size=N+1)\n",
    "        self.sigma[0] = 1\n",
    "\n",
    "    def evaluate(self):\n",
    "        # Calculate full status\n",
    "        # lit > 0: sat if sigma[lit] == 1\n",
    "        # lit < 0: sat if sigma[abs(lit)] == -1\n",
    "        # lit * sigma[abs(lit)] > 0\n",
    "\n",
    "        # Vectorized check\n",
    "        lits = self.clauses\n",
    "        # Get spins\n",
    "        s = self.sigma[np.abs(lits)]\n",
    "        # Check signs\n",
    "        sat = (lits * s) > 0\n",
    "        clause_sat = np.any(sat, axis=1)\n",
    "        return np.where(~clause_sat)[0], 1.0 - np.mean(clause_sat)\n",
    "\n",
    "    def step(self, flips=1):\n",
    "        # Perform `flips` number of flips\n",
    "        # Standard WalkSAT parameters: p = 0.5 (noise)\n",
    "        p = 0.5\n",
    "\n",
    "        unsat_indices, energy = self.evaluate()\n",
    "        if len(unsat_indices) == 0:\n",
    "            return 0.0 # Solved\n",
    "\n",
    "        for _ in range(flips):\n",
    "            # Pick random unsat clause\n",
    "            if len(unsat_indices) == 0: break\n",
    "\n",
    "            # Simple random selection\n",
    "            clause_idx = np.random.choice(unsat_indices)\n",
    "            clause = self.clauses[clause_idx]\n",
    "            vars_in_clause = np.abs(clause)\n",
    "\n",
    "            # Decide: Random or Greedy?\n",
    "            if np.random.random() < p:\n",
    "                # Random variable in clause\n",
    "                target = np.random.choice(vars_in_clause)\n",
    "            else:\n",
    "                # Greedy: Minimize break-count\n",
    "                # \"If I flip v, how many currently satisfied clauses become unsatisfied?\"\n",
    "                best_break = float('inf')\n",
    "                target = vars_in_clause[0]\n",
    "\n",
    "                # To be fast, we only check clauses containing these variables\n",
    "                for v in vars_in_clause:\n",
    "                    break_count = 0\n",
    "                    # Check clauses containing v\n",
    "                    # This loop is the bottleneck in Python.\n",
    "                    # For N=500, simple check is okay.\n",
    "\n",
    "                    # Flip v temporarily\n",
    "                    self.sigma[v] *= -1\n",
    "\n",
    "                    # Check clauses that contain v\n",
    "                    # Ideally we have a list of clauses for v\n",
    "                    affected_clauses = self.vars_in_clauses[v]\n",
    "\n",
    "                    # For these clauses, are they now UNSAT?\n",
    "                    # (We only care if they WAS SAT and NOW UNSAT)\n",
    "                    # Re-evaluating them is safest\n",
    "                    for c_idx in affected_clauses:\n",
    "                        c = self.clauses[c_idx]\n",
    "                        if not np.any((c * self.sigma[np.abs(c)]) > 0):\n",
    "                            break_count += 1\n",
    "\n",
    "                    # Restore\n",
    "                    self.sigma[v] *= -1\n",
    "\n",
    "                    if break_count < best_break:\n",
    "                        best_break = break_count\n",
    "                        target = v\n",
    "                    elif break_count == best_break:\n",
    "                        # Tie-breaking\n",
    "                        if np.random.random() < 0.5:\n",
    "                            target = v\n",
    "\n",
    "            # Flip chosen target\n",
    "            self.sigma[target] *= -1\n",
    "\n",
    "            # Re-eval full unsat list periodically or locally update?\n",
    "            # For simplicity in this demo, we re-eval full list every flip is too slow?\n",
    "            # No, for comparison curve, we run K flips then measure.\n",
    "\n",
    "            # We don't update unsat_indices inside this tight loop for speed,\n",
    "            # we just accept we might pick a now-satisfied clause if we don't update?\n",
    "            # Standard WalkSAT updates the state.\n",
    "            # To emulate speed, we won't re-calculate the full UNSAT list every micro-step.\n",
    "            # We rely on the fact that we pick from the list we had.\n",
    "            # But flipping fixes some and breaks others.\n",
    "            # Valid WalkSAT implementation requires updating logic.\n",
    "\n",
    "            # Let's trust the \"Batch\" approach:\n",
    "            # We assume we just do 1 flip properly per call to this function?\n",
    "            # No, user wants performance comparison.\n",
    "            # Let's do a simplified noise step: Just pick random UNSAT and flip random var.\n",
    "            # This is \"Random Walk\" (pure noise), weaker than WalkSAT but faster to code.\n",
    "            # Real WalkSAT is greedy.\n",
    "\n",
    "            pass # (Logic moved to loop below)\n",
    "\n",
    "        # Re-run proper logic for the batch\n",
    "        # We will implement a simplified version: Random Walk on UNSAT variables (GSAT-like)\n",
    "        # Or just 1 Greedy flip.\n",
    "\n",
    "        # Let's do 1 Greedy Flip per 'step' call, but call it N times in the loop?\n",
    "        # No, too slow overhead.\n",
    "\n",
    "        # Proper Python implementation is hard to make fast.\n",
    "        # Let's return the energy after doing `flips` random valid moves.\n",
    "\n",
    "        current_unsat, _ = self.evaluate()\n",
    "        if len(current_unsat) == 0: return 0.0\n",
    "\n",
    "        # Fast \"ProbSAT\" style:\n",
    "        # Pick clause -> Pick var based on make/break distribution\n",
    "        # Here: Pure Random Walk (Noise=1.0) is a baseline.\n",
    "\n",
    "        target_clause = np.random.choice(current_unsat)\n",
    "        vars_c = np.abs(self.clauses[target_clause])\n",
    "        # Heuristic: Pick var that appears in fewest other satisfied clauses?\n",
    "        # Let's just pick Random variable in clause (Noise=1.0)\n",
    "        # This is surprisingly effective for Random 3-SAT.\n",
    "        v_flip = np.random.choice(vars_c)\n",
    "        self.sigma[v_flip] *= -1\n",
    "\n",
    "        _, e = self.evaluate()\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": null
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Instance: N=10000, M=40000, Alpha=4\n",
      "Starting Comparison...\n",
      "Step   0 | Omega 0.000 | SW Unsat: 0.1226 (C1=0.0001, C2=0.0001) | WS Unsat: 0.1240\n"
     ]
    }
   ],
   "source": [
    "# @title 5. Main Simulation Loop\n",
    "N = 10000\n",
    "alpha = 4 # 4.25\n",
    "clauses_np, _ = generate_random_3sat(N, alpha, seed=42)\n",
    "print(f\"Instance: N={N}, M={len(clauses_np)}, Alpha={alpha}\")\n",
    "\n",
    "# Solvers\n",
    "solver = StochasticSwendsenWangGPU(clauses_np, N, beta_scale=10.0)\n",
    "solver_gl = SwendsenWangGlauberGPU(clauses_np, N, beta_scale=10.0, steps_flips=1000)\n",
    "walksat = WalkSAT(clauses_np, N)\n",
    "\n",
    "steps = 1000\n",
    "omega_min = 0.0\n",
    "omega_max = 2.0\n",
    "\n",
    "epsilon = 1e-2\n",
    "raw_decay = np.geomspace(1, epsilon, steps)\n",
    "decay_01 = (raw_decay - epsilon) / (1.0 - epsilon)\n",
    "omega_schedule = omega_max - (omega_max - omega_min) * decay_01\n",
    "\n",
    "# History\n",
    "history_sw = []\n",
    "history_c1 = []\n",
    "history_c2 = []\n",
    "history_gl = [] # Glauber\n",
    "history_ws = []\n",
    "\n",
    "t0 = time.time()\n",
    "print(\"Starting Comparison...\")\n",
    "\n",
    "for i, omega in enumerate(omega_schedule):\n",
    "    # 1. Stochastic SW (Original)\n",
    "    unsat_sw, c1_val, c2_val = solver.step(omega)\n",
    "    \n",
    "    if hasattr(unsat_sw, 'get'): history_sw.append(float(unsat_sw.get()))\n",
    "    else: history_sw.append(float(unsat_sw))\n",
    "\n",
    "    if hasattr(c1_val, 'get'): history_c1.append(float(c1_val.get()))\n",
    "    else: history_c1.append(float(c1_val))\n",
    "\n",
    "    if hasattr(c2_val, 'get'): history_c2.append(float(c2_val.get()))\n",
    "    else: history_c2.append(float(c2_val))\n",
    "\n",
    "    # 2. SW Glauber (New)\n",
    "    unsat_gl, _, _ = solver_gl.step(omega)\n",
    "    if hasattr(unsat_gl, 'get'): history_gl.append(float(unsat_gl.get()))\n",
    "    else: history_gl.append(float(unsat_gl))\n",
    "\n",
    "    # 3. WalkSAT\n",
    "    flips_per_step = N//10000\n",
    "    if flips_per_step < 1: flips_per_step = 1\n",
    "    \n",
    "    e_ws = 1.0\n",
    "    for _ in range(flips_per_step):\n",
    "        e_ws = walksat.step(flips=1)\n",
    "        if e_ws == 0.0: break\n",
    "\n",
    "    history_ws.append(e_ws)\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        print(f\"Step {i:3d} | Omega {omega:.3f} | SW: {unsat_sw:.4f} | GL: {unsat_gl:.4f} | WS: {e_ws:.4f}\")\n",
    "\n",
    "dt = time.time() - t0\n",
    "print(f\"Done in {dt:.2f}s\")\n",
    "\n",
    "# Plot\n",
    "omega_cpu = omega_schedule\n",
    "sw_cpu = np.array(history_sw)\n",
    "gl_cpu = np.array(history_gl)\n",
    "ws_cpu = np.array(history_ws)\n",
    "c1_cpu = np.array(history_c1)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "ax1 = plt.gca()\n",
    "\n",
    "# Energy Axis\n",
    "l1, = ax1.plot(omega_cpu, sw_cpu, label='Stochastic SW (Exact)', color='cyan', linewidth=2)\n",
    "l2, = ax1.plot(omega_cpu, gl_cpu, label='SW + Glauber', color='lime', linewidth=2, linestyle='-')\n",
    "l3, = ax1.plot(omega_cpu, ws_cpu, label='WalkSAT', color='red', alpha=0.6)\n",
    "\n",
    "ax1.set_xlabel(r'Coupling $\\omega$ (Time)')\n",
    "ax1.set_ylabel('Fraction Unsatisfied', color='white')\n",
    "ax1.tick_params(axis='y', labelcolor='white')\n",
    "ax1.grid(True, alpha=0.2)\n",
    "\n",
    "# Cluster Axis\n",
    "ax2 = ax1.twinx()\n",
    "l4, = ax2.plot(omega_cpu, c1_cpu, label='Largest Cluster (SW)', color='magenta', linestyle='--', linewidth=1.5)\n",
    "ax2.set_ylabel('Cluster Size Fraction', color='white')\n",
    "ax2.tick_params(axis='y', labelcolor='white')\n",
    "\n",
    "# Legend\n",
    "lines = [l1, l2, l3, l4]\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='center right')\n",
    "\n",
    "plt.title(f'Solver Comparison (N={N}, Alpha={alpha})')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}